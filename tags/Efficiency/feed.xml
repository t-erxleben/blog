<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
    <generator uri="https://gohugo.io/" version="0.92.2">Hugo</generator>
    <title>Efficiency on Parallel Computing and I/O Blog</title>
        <subtitle>We conduct research and development on parallel systems</subtitle>
            <link href="https://blog.parcio.de/tags/Efficiency/" rel="alternate" type="text/html" title="HTML" />
            <link href="https://blog.parcio.de/tags/Efficiency/feed.xml" rel="self" type="application/atom+xml" title="Atom" />
    <updated>2022-05-15T21:51:28+00:00</updated>
    <id>https://blog.parcio.de/tags/Efficiency/</id>
        <entry>
            <title>Libfabric: A generalized way for fabric communication</title>
            <link href="https://blog.parcio.de/posts/2022/04/libfabric/" rel="alternate" type="text/html"  hreflang="en" />
            <id>https://blog.parcio.de/posts/2022/04/libfabric/</id>
                    <author>
                        <name>Julian Benda</name>
                    </author>
            <published>2022-04-25T00:00:00+00:00</published>
            <updated>2022-04-25T00:00:00+00:00</updated>
            <content type="html">
                &lt;p&gt;In this post, we will look at the challenges of efficient communication between processes and how Libfabric abstracts them.
We will see how OFI (Open Fabrics Interfaces) enables a fast and generalized communication.&lt;/p&gt;
&lt;style&gt;
@media(prefers-color-scheme: dark) {
	html.color-toggle-auto .light-only {
		display: none;
	}
}
@media(prefers-color-scheme: light) {
	html.color-toggle-auto .dark-only {
		display: none;
	}
}
html.color-toggle-dark .light-only {
	display: none;
}
html.color-toggle-light .dark-only {
	display: none;
}
&lt;/style&gt;
&lt;div class=&#34;gblog-post__anchorwrap&#34;&gt;
    &lt;h2 id=&#34;what-is-a-fabric-and-how-to-communicate-in-it&#34;&gt;
        What is a fabric and how to communicate in it?
        &lt;a data-clipboard-text=&#34;https://blog.parcio.de/posts/2022/04/libfabric/#what-is-a-fabric-and-how-to-communicate-in-it&#34; class=&#34;gblog-post__anchor gblog-post__anchor--right clip&#34; aria-label=&#34;Anchor What is a fabric and how to communicate in it?&#34; href=&#34;#what-is-a-fabric-and-how-to-communicate-in-it&#34;&gt;
            &lt;svg class=&#34;icon gblog_link&#34;&gt;&lt;use xlink:href=&#34;#gblog_link&#34;&gt;&lt;/use&gt;&lt;/svg&gt;
        &lt;/a&gt;
    &lt;/h2&gt;
&lt;/div&gt;
&lt;p&gt;A fabric is nothing more or less than several, more or less uniform, nodes connected via links or, in other words, the typical HPC or cloud computing landscape.&lt;/p&gt;
&lt;p&gt;Nodes can be linked via different physical media (e.g., copper or optical fiber) and various communication protocols. 
While the physical medium is hidden behind the network cards, the communication protocol is something we still need to manage in user-space because different protocols require other interactions with the network to function.&lt;/p&gt;
&lt;p&gt;To have a unified interface for the typical messaging data transfer would be nice, while not necessarily being a game changer.
But in perspective to RDMA, it differs.&lt;/p&gt;
&lt;div class=&#34;gblog-post__anchorwrap&#34;&gt;
    &lt;h2 id=&#34;rdma&#34;&gt;
        RDMA
        &lt;a data-clipboard-text=&#34;https://blog.parcio.de/posts/2022/04/libfabric/#rdma&#34; class=&#34;gblog-post__anchor gblog-post__anchor--right clip&#34; aria-label=&#34;Anchor RDMA&#34; href=&#34;#rdma&#34;&gt;
            &lt;svg class=&#34;icon gblog_link&#34;&gt;&lt;use xlink:href=&#34;#gblog_link&#34;&gt;&lt;/use&gt;&lt;/svg&gt;
        &lt;/a&gt;
    &lt;/h2&gt;
&lt;/div&gt;
&lt;p&gt;Remote direct memory access (RDMA) sounds counter intuitive at first, because how would you access remote memory directly?
Directly in this context means without involving the operating system and CPU.
Instead, the data transfer is entirely managed by the NIC.
Therefore, we only need to signal we want to read data X from source Y to the memory segment Z, and the NIC does the rest.&lt;/p&gt;
&lt;p&gt;In contrast, for normal kernel mode networking, we will copy the buffer multiple times and run it through various layers of code (e.g., socket, TCP protocol implementation, and driver).
This will cause a load on the CPU and bus, while RDMA, thanks to kernel bypass to the NIC, can offload a huge part from the network stack.&lt;/p&gt;
&lt;p&gt;This opens many questions, to name a few:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;When is the memory transfer finished?&lt;/li&gt;
&lt;li&gt;How to avoid inconsistency due to invalidated caches?&lt;/li&gt;
&lt;li&gt;Is RDMA even possible with this NIC?&lt;/li&gt;
&lt;li&gt;How to queue RDMA requests?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The answers to these questions depend strongly on the implementation and the network protocol.
Therefore, a unified solution is quite welcome if you want the flexibility to change your link type.&lt;/p&gt;
&lt;p&gt;A short reminder: RDMA still uses the same network as typical network messages, therefore the bandwidth and latency will not change much, but it will reduce the work done by the CPU, which leads to fewer interrupts and more processing time for your calculation running.&lt;/p&gt;
&lt;div class=&#34;gblog-post__anchorwrap&#34;&gt;
    &lt;h2 id=&#34;libfabric-abstraction&#34;&gt;
        Libfabric abstraction
        &lt;a data-clipboard-text=&#34;https://blog.parcio.de/posts/2022/04/libfabric/#libfabric-abstraction&#34; class=&#34;gblog-post__anchor gblog-post__anchor--right clip&#34; aria-label=&#34;Anchor Libfabric abstraction&#34; href=&#34;#libfabric-abstraction&#34;&gt;
            &lt;svg class=&#34;icon gblog_link&#34;&gt;&lt;use xlink:href=&#34;#gblog_link&#34;&gt;&lt;/use&gt;&lt;/svg&gt;
        &lt;/a&gt;
    &lt;/h2&gt;
&lt;/div&gt;
&lt;p&gt;Libfabric offers a unified interface to use different communication types over different communication protocols, and each time tries to minimize the overhead.&lt;/p&gt;
&lt;p&gt;The supported communication types are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Message Queue: Message-based FIFO queue&lt;/li&gt;
&lt;li&gt;Tagged Message Queue: Similar to Message Queue but enables operations based on a 64-bit tag attached to each message&lt;/li&gt;
&lt;li&gt;RMA (remote memory access): Abstraction of RDMA to enable it also on systems that are not RDMA-capable&lt;/li&gt;
&lt;li&gt;Atomic: Allow atomic operations at the network level&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a
  class=&#34;gblog-markdown__link&#34;
  href=&#34;https://github.com/julea-io/julea&#34;
  
&gt;JULEA&lt;/a&gt; is a flexible storage framework for clusters that allows offering arbitrary I/O interfaces to applications.
It runs completely in user space, which eases development and debugging.
Because it runs on a cluster, a lot of network communication must be handled.
Until now, it used TCP (via &lt;code&gt;GSocket&lt;/code&gt;).
While TCP connections normally work everywhere, the cluster may provide better fabrics, which we were unable to use.
Now, with Libfabric, we can use a huge variety of other fabrics like InfiniBand.&lt;/p&gt;
&lt;p&gt;For JULEA, Message Queue and RMA are the most interesting.
Message Queue fits the communication structure currently used in JULEA.
RMA enables processing many data transfers in parallel.
With RMA, we can, for example, process a message with multiple read access and tell the link that the data have no specific order.&lt;/p&gt;
&lt;p&gt;To achieve this, Libfabric uses different abstracted modules, where each of them is equipped with an optional argument to even use it only for one protocol or just let Libfabric decide what is best.&lt;/p&gt;
&lt;p&gt;Each module enables us to create the next in the chain until we archive the connection we want.
The modules of interest are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fabric information: List of available networks, which can be filtered and is sorted by performance&lt;/li&gt;
&lt;li&gt;Fabric: All resources needed to use a network&lt;/li&gt;
&lt;li&gt;Domain: Represents a connection in a fabric (e.g., a port or a NIC)&lt;/li&gt;
&lt;li&gt;Endpoint: Communication portal to a domain&lt;/li&gt;
&lt;li&gt;Event queue: Reports asynchronous meta events for an endpoint, like connection established/shutdown&lt;/li&gt;
&lt;li&gt;Completion queue/counter: High-performance queue reports completed data transfers or just a counter&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If we want, for example, to build a connection to a server (with a known address), we can use &lt;code&gt;fi_getinfo&lt;/code&gt; to request all available fabrics which are capable of connecting to the server.&lt;/p&gt;
&lt;p&gt;Then we pick the first of them (because this is likely the most performant) and construct a fabric.
After this because we do not have special requirements (and have already defined our communication destination), we just create a domain at that fabric and then an endpoint with event and completion counter at that.&lt;/p&gt;
&lt;p&gt;With the endpoint, we get a connect request that needs to be accepted from the server and confirmed via a &lt;code&gt;FI_CONNECTED&lt;/code&gt; in the event queue.&lt;/p&gt;
&lt;p&gt;Now each time the completion counter increases, we know something has happened; for simple communication, this is enough.
We can bind different counters or queues to this if we want to differ between incoming and outgoing completion.
Queues enable us also to keep track of an action based on a context we may freely choose (it is basically an ID).&lt;/p&gt;
&lt;p&gt;If you want a more detailed explanation, the official introduction to the interface can be found &lt;a
  class=&#34;gblog-markdown__link&#34;
  href=&#34;https://ofiwg.github.io/libfabric/v1.13.2/man/fabric.7.html&#34;
  
&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;gblog-post__anchorwrap&#34;&gt;
    &lt;h2 id=&#34;conclusion-and-first-measurements&#34;&gt;
        Conclusion and first measurements
        &lt;a data-clipboard-text=&#34;https://blog.parcio.de/posts/2022/04/libfabric/#conclusion-and-first-measurements&#34; class=&#34;gblog-post__anchor gblog-post__anchor--right clip&#34; aria-label=&#34;Anchor Conclusion and first measurements&#34; href=&#34;#conclusion-and-first-measurements&#34;&gt;
            &lt;svg class=&#34;icon gblog_link&#34;&gt;&lt;use xlink:href=&#34;#gblog_link&#34;&gt;&lt;/use&gt;&lt;/svg&gt;
        &lt;/a&gt;
    &lt;/h2&gt;
&lt;/div&gt;
&lt;p&gt;Libfabric allows using different fabrics with the same interface.
This way, you can write RDMA-compatible code, and Libfabric makes it also work on a system that does not support RDMA.&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;light-only&#34;&gt;&lt;img src=&#34;julea-gsocket-vs-libfabric-operations.png&#34;
         alt=&#34;Comparing the performance of JULEA with GSocket using the operations per second for object creation and deletion. This shows that the performance via TCP is slightly in favor of Libfabric and that InfiniBand is multiple orders of magnitude faster than TCP, but impossible to use with GSocket.&#34;/&gt;&lt;figcaption&gt;
            &lt;p&gt;Comparing the performance of JULEA with GSocket using the operations per second for object creation and deletion. This shows that the performance via TCP is slightly in favor of Libfabric and that InfiniBand is multiple orders of magnitude faster than TCP, but impossible to use with GSocket.&lt;/p&gt;
        &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure class=&#34;light-only&#34;&gt;&lt;img src=&#34;julea-gsocket-vs-libfabric-throughput.png&#34;
         alt=&#34;Comparing performance of JULEA with GSocket and Libfabric network code using the througput of read and write operations. Shows that performance via TCP is similar, while performance via InfiniBand with Libfabric is multiple orders of mangitude faster, while impossible to use with GSocket.&#34;/&gt;&lt;figcaption&gt;
            &lt;p&gt;Comparing performance of JULEA with GSocket and Libfabric network code using the througput of read and write operations. Shows that performance via TCP is similar, while performance via InfiniBand with Libfabric is multiple orders of mangitude faster, while impossible to use with GSocket.&lt;/p&gt;
        &lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;dark-only&#34;&gt;&lt;img src=&#34;julea-gsocket-vs-libfabric-operations-dark.png&#34;
         alt=&#34;Comparing the performance of JULEA with GSocket using the operations per second for object creation and deletion. This shows that the performance via TCP is slightly in favor of Libfabric and that InfiniBand is multiple orders of magnitude faster than TCP, but impossible to use with GSocket.&#34;/&gt;&lt;figcaption&gt;
            &lt;p&gt;Comparing the performance of JULEA with GSocket using the operations per second for object creation and deletion. This shows that the performance via TCP is slightly in favor of Libfabric and that InfiniBand is multiple orders of magnitude faster than TCP, but impossible to use with GSocket.&lt;/p&gt;
        &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure class=&#34;dark-only&#34;&gt;&lt;img src=&#34;julea-gsocket-vs-libfabric-throughput-dark.png&#34;
         alt=&#34;Comparing performance of JULEA with GSocket and Libfabric network code using the througput of read and write operations. Shows that performance via TCP is similar, while performance via InfiniBand with Libfabric is multiple orders of mangitude faster, while impossible to use with GSocket.&#34;/&gt;&lt;figcaption&gt;
            &lt;p&gt;Comparing performance of JULEA with GSocket and Libfabric network code using the througput of read and write operations. Shows that performance via TCP is similar, while performance via InfiniBand with Libfabric is multiple orders of mangitude faster, while impossible to use with GSocket.&lt;/p&gt;
        &lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;We already tested it in JULEA.
We rewrote the &lt;code&gt;GSocket&lt;/code&gt; network code with Libfabric.
This resulted in working InfiniBand and RDMA support.
But also without RDMA, its performance is still similar to the &lt;code&gt;GSocket&lt;/code&gt; implementation.&lt;/p&gt;
&lt;p&gt;Therefore, Libfabric enables to use the most efficient fabric available without having to modify the code.&lt;/p&gt;
            </content>  
                                <category scheme="https://blog.parcio.de/authors/julian.benda" term="julian.benda" label="julian.benda" />  
                                <category scheme="https://blog.parcio.de/tags/Efficiency" term="Efficiency" label="Efficiency" /> 
                                <category scheme="https://blog.parcio.de/tags/Network-Communication" term="Network-Communication" label="Network Communication" /> 
                                <category scheme="https://blog.parcio.de/tags/Libfabric" term="Libfabric" label="Libfabric" />
        </entry>
        <entry>
            <title>Performance of conditional operator vs. fabs</title>
            <link href="https://blog.parcio.de/posts/2021/09/conditional-vs-fabs/" rel="alternate" type="text/html"  hreflang="en" />
            <id>https://blog.parcio.de/posts/2021/09/conditional-vs-fabs/</id>
                    <author>
                        <name>Michael Kuhn</name>
                    </author>
            <published>2021-09-21T00:00:00+00:00</published>
            <updated>2021-09-21T00:00:00+00:00</updated>
            <content type="html">
                &lt;p&gt;Today, we will take a look at potential performance problems when using the conditional operator &lt;code&gt;?:&lt;/code&gt;.
Specifically, we will use it to calculate a variable&amp;rsquo;s absolute value and compare its performance with that of the function &lt;code&gt;fabs&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Assume the following numerical code written in C, where we need to calculate the absolute value of a &lt;code&gt;double&lt;/code&gt; variable called &lt;code&gt;residuum&lt;/code&gt;.&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;
Since we want to perform this operation within the inner loop, we will have to keep performance overhead as low as possible.
To reduce dependencies on math libraries and avoid function call overhead, we manually get the absolute value by first checking whether &lt;code&gt;residuum&lt;/code&gt; is less than &lt;code&gt;0&lt;/code&gt; and, if it is, negating it using the &lt;code&gt;-&lt;/code&gt; operator.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;hl&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;j&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;j&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;j&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
	&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
		&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
		&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;span class=&#34;hl&#34;&gt;			&lt;span class=&#34;n&#34;&gt;residuum&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;residuum&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;?&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nl&#34;&gt;residuum&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;residuum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;		&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
	&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;This looks easy enough and, in theory, should provide satisfactory performance.
Just to be sure, let&amp;rsquo;s do the same using the &lt;code&gt;fabs&lt;/code&gt; function from the math library, which returns the absolute value of a floating-point number.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;hl&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;j&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;j&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;j&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
	&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
		&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
		&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;span class=&#34;hl&#34;&gt;			&lt;span class=&#34;n&#34;&gt;residuum&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fabs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;residuum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;		&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
	&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Let&amp;rsquo;s compare the two implementations using &lt;a
  class=&#34;gblog-markdown__link&#34;
  href=&#34;https://github.com/sharkdp/hyperfine&#34;
  
&gt;hyperfine&lt;/a&gt;.&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;hl&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-plain&#34; data-lang=&#34;plain&#34;&gt;Benchmark #1: ./conditional
  Time (mean ± σ):     476.3 ms ±   0.4 ms    [User: 474.5 ms, System: 0.7 ms]
  Range (min … max):   475.6 ms … 476.8 ms    10 runs

Benchmark #2: ./fabs
  Time (mean ± σ):     243.8 ms ±   2.0 ms    [User: 242.2 ms, System: 0.8 ms]
  Range (min … max):   242.1 ms … 249.0 ms    12 runs

Summary
  &amp;#39;./fabs&amp;#39; ran
&lt;span class=&#34;hl&#34;&gt;    1.95 ± 0.02 times faster than &amp;#39;./conditional&amp;#39;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;As we can see, the &lt;code&gt;fabs&lt;/code&gt; implementation ran faster by more than a factor of 1.9!
Where does this massive performance difference come from?
Let&amp;rsquo;s use &lt;code&gt;perf stat&lt;/code&gt; to analyze the two implementations in a bit more detail.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;hl&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;hl&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-plain&#34; data-lang=&#34;plain&#34;&gt;Performance counter stats for &amp;#39;./conditional&amp;#39;:

           478,51 msec task-clock:u              #    0,998 CPUs utilized
                0      context-switches:u        #    0,000 /sec
                0      cpu-migrations:u          #    0,000 /sec
               55      page-faults:u             #  114,940 /sec
&lt;span class=&#34;hl&#34;&gt;    2.035.211.626      cycles:u                  #    4,253 GHz                      (83,28%)
&lt;/span&gt;        1.592.587      stalled-cycles-frontend:u #    0,08% frontend cycles idle     (83,28%)
          223.899      stalled-cycles-backend:u  #    0,01% backend cycles idle      (83,28%)
&lt;span class=&#34;hl&#34;&gt;    4.009.332.175      instructions:u            #    1,97  insn per cycle
&lt;/span&gt;                                                 #    0,00  stalled cycles per insn  (83,32%)
    2.001.712.079      branches:u                #    4,183 G/sec                    (83,49%)
        1.503.325      branch-misses:u           #    0,08% of all branches          (83,34%)

      0,479296441 seconds time elapsed

      0,474423000 seconds user
      0,001996000 seconds sys
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;The most important metrics here are the number of instructions and the number of cycles.
Our processor can run around 4,250,000,000 cycles per second, resulting in a runtime of 0.48 seconds to process the roughly 4,000,000,000 instructions at 1.97 instructions per cycle.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;hl&#34;&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;hl&#34;&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-plain&#34; data-lang=&#34;plain&#34;&gt;Performance counter stats for &amp;#39;./fabs&amp;#39;:

           245,48 msec task-clock:u              #    0,997 CPUs utilized
                0      context-switches:u        #    0,000 /sec
                0      cpu-migrations:u          #    0,000 /sec
               51      page-faults:u             #  207,757 /sec
&lt;span class=&#34;hl&#34;&gt;    1.039.265.407      cycles:u                  #    4,234 GHz                      (83,31%)
&lt;/span&gt;        1.720.716      stalled-cycles-frontend:u #    0,17% frontend cycles idle     (83,30%)
          356.067      stalled-cycles-backend:u  #    0,03% backend cycles idle      (83,30%)
&lt;span class=&#34;hl&#34;&gt;    3.007.112.338      instructions:u            #    2,89  insn per cycle
&lt;/span&gt;                                                 #    0,00  stalled cycles per insn  (83,29%)
    1.003.303.373      branches:u                #    4,087 G/sec                    (83,46%)
        1.662.984      branch-misses:u           #    0,17% of all branches          (83,34%)

      0,246272015 seconds time elapsed

      0,243024000 seconds user
      0,000977000 seconds sys
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;The reduction from 2,000,000,000 to 1,000,000,000 cycles corresponds to the performance improvement of 1.95.
Using the &lt;code&gt;fabs&lt;/code&gt; function reduced the number of instructions by roughly 25% and, at the same time, increased the number of instructions per cycle to 2.89 (a factor of 1.47).
Getting rid of the conditional operator reduced the number of branches by half, allowing the processor to process more instructions per cycle.
The conditional operator is more or less a short-hand version of the &lt;code&gt;if&lt;/code&gt; statement and introduced a significant number of branches into our inner loop.&lt;/p&gt;
&lt;p&gt;Running three nested loops with 1,000 iterations each resulted in 1,000,000,000 inner loop iterations, that is, we saved one instruction per inner loop iteration.
These branch and instruction differences can be checked in even more detail using &lt;code&gt;objdump -S&lt;/code&gt;; this is left as an exercise for the reader.&lt;/p&gt;
&lt;p&gt;The magnitude of these performance differences is rather surprising and shows that it makes sense to check even seemingly simple code for potential performance problems.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;The code shown is only an excerpt, the full code is available &lt;a
  class=&#34;gblog-markdown__link&#34;
  href=&#34;conditional-vs-fabs.c&#34;
  
&gt;here&lt;/a&gt;. It was compiled with GCC 11.2 using the &lt;code&gt;-O2 -Wall -Wextra -Wpedantic&lt;/code&gt; flags and the &lt;code&gt;-lm&lt;/code&gt; library.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;hyperfine performs a statistical performance analysis. It runs the provided commands multiple times to reduce the influence of random errors and calculates derived metrics such as the mean and standard deviation.&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
            </content>  
                                <category scheme="https://blog.parcio.de/authors/michael.kuhn" term="michael.kuhn" label="michael.kuhn" />  
                                <category scheme="https://blog.parcio.de/tags/Efficiency" term="Efficiency" label="Efficiency" />
        </entry>
</feed>
